version: '3.8'

# Production Docker Compose for Trading Bot
# =========================================
# Optimized for production deployment with security, monitoring, and scaling
# Supports AWS ECS, GCP Cloud Run, Azure Container Instances

services:
  # Main Backend API - Node.js/TypeScript
  backend:
    build:
      context: ../../
      dockerfile: docker/Dockerfile.backend
      target: production
    image: ${REGISTRY_URL:-localhost}/trading-bot-backend:${VERSION:-latest}
    container_name: trading-backend-prod
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=${DATABASE_URL}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - ALPACA_API_KEY=${ALPACA_API_KEY}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY}
      - COINGECKO_API_KEY=${COINGECKO_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - COMPOSER_MCP_URL=${COMPOSER_MCP_URL}
      - ML_SERVICE_URL=http://ml-service:5000
      - RL_SERVICE_URL=http://rl-service:8001
      - METRICS_PORT=3001
      - PROMETHEUS_ENDPOINT=http://prometheus:9090
      - JAEGER_ENDPOINT=${JAEGER_ENDPOINT}
      - NEW_RELIC_LICENSE_KEY=${NEW_RELIC_LICENSE_KEY}
    depends_on:
      redis:
        condition: service_healthy
      influxdb:
        condition: service_healthy
      ml-service:
        condition: service_healthy
      rl-service:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - backend_logs:/app/logs:rw
      - /etc/ssl/certs:/etc/ssl/certs:ro
    networks:
      - trading-network
      - monitoring-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
      replicas: 2
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 60s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=backend,environment=production"

  # ML Service - Python/Flask for Adaptive Threshold
  ml-service:
    build:
      context: ../../ml-service
      dockerfile: Dockerfile.ml-service
      target: production
    image: ${REGISTRY_URL:-localhost}/trading-bot-ml:${VERSION:-latest}
    container_name: trading-ml-prod
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - FLASK_DEBUG=0
      - DATABASE_URL=${DATABASE_URL}
      - COMPOSER_MCP_URL=${COMPOSER_MCP_URL}
      - REDIS_URL=redis://redis:6379
      - MODEL_CACHE_SIZE=${MODEL_CACHE_SIZE:-1000}
      - WORKER_PROCESSES=${ML_WORKERS:-4}
      - METRICS_PORT=5001
    depends_on:
      redis:
        condition: service_healthy
      influxdb:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ml_models:/app/models:rw
      - ml_logs:/app/logs:rw
      - ml_cache:/app/cache:rw
    networks:
      - trading-network
      - monitoring-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 90s
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G
      replicas: 2
      update_config:
        parallelism: 1
        delay: 45s
        failure_action: rollback
        monitor: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=ml-service,environment=production"

  # RL Service - Python/FastAPI for Reinforcement Learning
  rl-service:
    build:
      context: ../../rl-service
      dockerfile: Dockerfile
      target: production
    image: ${REGISTRY_URL:-localhost}/trading-bot-rl:${VERSION:-latest}
    container_name: trading-rl-prod
    ports:
      - "8001:8001"
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379
      - MODEL_PATH=/app/models
      - TRAINING_ENABLED=${RL_TRAINING_ENABLED:-false}
      - INFERENCE_WORKERS=${RL_WORKERS:-2}
      - GPU_ENABLED=${GPU_ENABLED:-false}
      - METRICS_PORT=8002
    depends_on:
      redis:
        condition: service_healthy
      influxdb:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - rl_models:/app/models:rw
      - rl_logs:/app/logs:rw
      - rl_data:/app/data:rw
    networks:
      - trading-network
      - monitoring-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/api/v1/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    deploy:
      resources:
        limits:
          cpus: '6.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 2G
      replicas: 1  # RL models are stateful, single instance for now
      update_config:
        parallelism: 1
        delay: 60s
        failure_action: rollback
        monitor: 180s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=rl-service,environment=production"

  # Redis - Caching and Message Queue
  redis:
    image: redis:7.2-alpine
    container_name: trading-redis-prod
    ports:
      - "6379:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    volumes:
      - redis_data:/data:rw
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
    restart: unless-stopped
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    networks:
      - trading-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # InfluxDB - Time Series Database
  influxdb:
    image: influxdb:2.7-alpine
    container_name: trading-influxdb-prod
    ports:
      - "8086:8086"
    environment:
      - INFLUXDB_DB=trading_bot
      - INFLUXDB_ADMIN_USER=${INFLUXDB_ADMIN_USER:-admin}
      - INFLUXDB_ADMIN_PASSWORD=${INFLUXDB_ADMIN_PASSWORD}
      - INFLUXDB_USER=${INFLUXDB_USER:-trader}
      - INFLUXDB_USER_PASSWORD=${INFLUXDB_USER_PASSWORD}
      - INFLUXDB_RETENTION_POLICY=${INFLUXDB_RETENTION:-30d}
    volumes:
      - influxdb_data:/var/lib/influxdb2:rw
      - influxdb_config:/etc/influxdb2:rw
      - ./influxdb-init.sh:/docker-entrypoint-initdb.d/init.sh:ro
    restart: unless-stopped
    networks:
      - trading-network
      - monitoring-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # Nginx - Load Balancer and Reverse Proxy
  nginx:
    image: nginx:1.25-alpine
    container_name: trading-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ssl:/etc/nginx/ssl:ro
      - nginx_cache:/var/cache/nginx:rw
      - nginx_logs:/var/log/nginx:rw
    depends_on:
      - backend
      - ml-service
      - rl-service
    restart: unless-stopped
    networks:
      - trading-network
      - monitoring-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: trading-prometheus-prod
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus:rw
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=${PROMETHEUS_RETENTION:-15d}'
      - '--storage.tsdb.retention.size=${PROMETHEUS_SIZE:-10GB}'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--web.external-url=${PROMETHEUS_EXTERNAL_URL}'
    restart: unless-stopped
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # Grafana - Monitoring Dashboard
  grafana:
    image: grafana/grafana:10.2.0
    container_name: trading-grafana-prod
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=${GRAFANA_PLUGINS:-grafana-clock-panel,grafana-simple-json-datasource}
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL}
      - GF_SMTP_ENABLED=${SMTP_ENABLED:-false}
      - GF_SMTP_HOST=${SMTP_HOST}
      - GF_SMTP_USER=${SMTP_USER}
      - GF_SMTP_PASSWORD=${SMTP_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana:rw
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
      - influxdb
    restart: unless-stopped
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # AlertManager - Alert Management
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: trading-alertmanager-prod
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager:rw
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=${ALERTMANAGER_EXTERNAL_URL}'
      - '--cluster.advertise-address=0.0.0.0:9093'
    restart: unless-stopped
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Jaeger - Distributed Tracing (Optional)
  jaeger:
    image: jaegertracing/all-in-one:1.50
    container_name: trading-jaeger-prod
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=memory
    restart: unless-stopped
    networks:
      - monitoring-network
    profiles:
      - tracing
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

# Named volumes for persistent data
volumes:
  # Application data
  redis_data:
    driver: local
  influxdb_data:
    driver: local
  influxdb_config:
    driver: local
  
  # Service-specific data
  backend_logs:
    driver: local
  ml_models:
    driver: local
  ml_logs:
    driver: local
  ml_cache:
    driver: local
  rl_models:
    driver: local
  rl_logs:
    driver: local
  rl_data:
    driver: local
  
  # Monitoring data
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  alertmanager_data:
    driver: local
  
  # Nginx data
  nginx_cache:
    driver: local
  nginx_logs:
    driver: local

# Networks for service isolation
networks:
  trading-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  monitoring-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16

# Production deployment configuration
# Use with: docker-compose -f docker-compose.prod.yml up -d
# Environment file: .env.production
# Registry: Set REGISTRY_URL for your container registry
# Scaling: docker-compose -f docker-compose.prod.yml up -d --scale backend=3